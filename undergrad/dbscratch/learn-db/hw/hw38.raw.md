
m4_include(setup.m4)

# Interactive - 38 - key word lookup

(Note this set of information is the basis for Assignment 03 on keywords)

PostgreSQL includes an extensive set of tools for key word lookup.   The word lookup is efficient and takes account of items like language and root words.

With regular SQL you have a pattern matching operator, `LIKE`.

```
m4_include(hw38_01.sql)
```

The `%` is wild card.  Because of the use of a wild car this kind of a query will usually result in a full table scan.  In some cases it is possible to use
a GIST index on the field and that will make the search faster.

PostgreSQL has an extended set of patterns that allows matching a wider set of values.  This is with the `SIMILAR TO` operator.

```
m4_include(hw38_02.sql)
```

PostgreSQL also includes the ability to use regular expressions on text fields.  This uses POSIX regular expressions.  The Operator is the tilde `~` operator.

```
m4_include(hw38_03.sql)
```

None of these takes account of things like "San Francisco"  is a single "term" in the English language.   Also things like "the" are not words that need to
be indexed.  Other languages like French have similar constructs.  PostgreSQL has an extensive set of capabilities for efficiently searching and indexing
text data.

Comparable tools are Lucine and Elastisearch.  Google also provides dedicated hardware for this kind of search.  All of these alternatives are very
expensive.  Many tolls can benefit from a search like this and at a cost of close to 0 (PostgreSQL is open source) this makes for a very interning
alternative.


## tsvector

The database uses a pair of values and an index.  The first of these is a `tsvector`.  This converts text into a set of words and locations.

```
SELECT to_tsvector('The quick brown fox jumped over the lazy dog.');  
```

Will result in

```
                      to_tsvector                      
-------------------------------------------------------
 'brown':3 'dog':9 'fox':4 'jump':5 'lazi':8 'quick':2
(1 row)
```

This set of data has "The" eliminated the "word" location for each word.  The words are converted into the root words.  "lazy" is 
confuted to "lazi" the root word.



## tsquery

`tsquery` is the query side of this along with the `@@` operator.

```
m4_include(hw38_04.sql)
```

Will return 't' for true.


```
m4_include(hw38_05.sql)
```

Will return 'f' for false.


The query processing also allows for operators in a query.

```
m4_include(hw38_06.sql)
```

Will return 't' for true.

There are and, `&`, or, `|` and  not, `!` operators.


## As a table

Let's put the tsvector data type into a table and add some data.

Run the file `hw38_07.sql`.

```
m4_include(hw38_07.sql)
```

Note the use of the `TSVECTOR` data type.

The insert will leave the `document_tokens` as a null field.  We will have to update the table to set
the tokens.  Also note that this ignores the "document_body" field.  We will get to that in a little bit.

```
m4_include(hw38_08.sql)
```

Let's query for a pair of words.


```
m4_include(hw38_09.sql)
```

Having to update the table after it is changed is far from ideal.   Let's replace this with
a trigger so that the tokens are always updated.    Also we will add a ranking and  the `document_body`.

Run the file `hw38_10.sql`:

```
m4_include(hw38_10.sql)
```

and we will add some data to verify that the trigger works.

Run the file `hw38_11.sql`:

```
m4_include(hw38_11.sql)
```

A select on the indexed_documents will show that all 4 rows have the `document_tokens` field 
filled in.


Now add an index to the field so that searches will be fast.

Run the file `hw38_12.sql`:

```
m4_include(hw38_12.sql)
```







#### Tags: "reverse key index","like","keyword"

#### Validate: SQL-Select,"select 'PASS' as x from ( select count(1) as x from indexed_documents where document_token is not null ) as t1 where t1.x = 4 "

#### FilesToRun: hw38_07.sql
#### FilesToRun: hw38_10.sql
#### FilesToRun: hw38_11.sql
#### FilesToRun: hw38_12.sql

